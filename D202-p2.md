## Collections

* collection columns are multi-valued columns
* designed a small amount of data
* retrieved in its entirety
* cannot nest a collection iside another collection ( unless using FROZEN )

#### SET

* unique values ( no duplicates )
* stored unordored but retrieved in sorted order
* example : CREATE TABLE person(name text,email set<text>);

#### LIST

* do not need to be unique
* stored in particular order

#### HASHMAP

* ordered by unique keys
* example : ALTER TABLE person ADD todo map<timestamp,text>;
UPDATE person SET todo={'2018-1-1':'study','2018-1-2':'work'} WHERE id='123'

#### Using Frozen in a collection

* used when you want to nest a collection inside a collection
* with serialize multiple components into a single value
* frozen collection are like a blob
* non-frozen types allow updates to individual fields


## UDTs ( user defined type )

* UDTs group related field of information
* attach multiple data fields
* allow any datatype including collections and UDTs
* allow embedding more complex data within a single column

## COUNTERS

* counter is a column used to store a 64bit signed integer
* changed incrementaly ( incremented or decremented )
* changed using UPDATE
* need special tables which have only primary and counter columns

#### Counter consideration
* distributed system can cause inconsistency
* cannot INSERT or assign value to count , default value start is 0
* not idempotent
* must be non-primary key column
* must use UPDATE command - DS Entreprise rejects UNSING TIMESTAMP or UNSING TTL to update counter columns
* can't be indexed or deleted

## UDF  & UDA 

#### UDF ( user defined function )
* write custom functions using Java and JavaScript
* used in SELECT , INSERT and UPDATE
* only available in the keyspace where it is defined
* enabled using the cassandra.yaml
    * Java : set enable_user_defined_functions to true
    * JavaScript : Set enable_scripted_user_defined_functions to true


#### UDA ( user defined aggregate )
* use the UDF to get data from the cluster
* query need to include only the aggregate function itself

## Data modeling methodology review

* steps :
      1. ( Conceptual data model + application workflow ) 
      2. ( Mapping conceptual to logical )
      3. ( Logical data model ) 
      4. ( Physical data model )
      5. ( Optimization tuning )

* if the application evolve and new queries are needed we just repeat this process to create the new needed tables.


## Conceptual data modeling

* in cassandra we model for performance ( we model for hadware behave)
* conceptual data model is :
   * abstract view of the domain ( object and relation between them )
   * technology independent
   * not specific to any database system
   

## Application workflow and access patterns

* cassandra is query driven 
* each application has a workflow - tasks/causal dependencies from a graph
* access patterns(task done by user of app ) help determine how data is accessed - know the queries you will run first


## Mapping conceptual to logical model

* Conceptual data model ( ERD ) + Access Patterns ( Queries)  ===> mapping rules and patterns ( chebotko Diagram ) ===> Logical data Model

* chebotko diagram contains
      * 







